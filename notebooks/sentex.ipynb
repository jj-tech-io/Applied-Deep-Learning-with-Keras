{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'py_torch_gpu_3_10' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'conda install -n py_torch_gpu_3_10 ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.layers import Dense, Flatten, Input\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "#import mnist\n",
    "import keras.datasets.mnist as mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "plt.imshow(x_train[0])\n",
    "plt.title(f\"image shape: {x_train[0].shape}\")\n",
    "plt.show()\n",
    "import keras\n",
    "from keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Input' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26952\\899835841.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mencoder_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"img\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mencoder_output\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"relu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"encoder\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Input' is not defined"
     ]
    }
   ],
   "source": [
    "encoder_input = Input(shape=(28, 28, 1), name=\"img\")\n",
    "x = layers.Flatten()(encoder_input)\n",
    "encoder_output = layers.Dense(64, activation=\"relu\")(x)\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "\n",
    "decoder_input =  layers.InputLayer(input_shape=(64,))(encoder_output)\n",
    "x = layers.Dense(784, activation=\"relu\")(decoder_input)\n",
    "decoder_output = layers.Reshape((28, 28, 1))(x)\n",
    "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "autoencoder = keras.Model(encoder_input, decoder_output, name=\"autoencoder\")\n",
    "# def decoder_loss(y_true, y_pred):\n",
    "#     return keras.losses.mean_squared_error(y_true, y_pred)\n",
    "# def encoder_loss(y_true, y_pred):\n",
    "#     return keras.losses.mean_squared_error(y_true, y_pred)\n",
    "# def end_to_end_loss(y_true, y_pred):\n",
    "#     return keras.losses.mean_squared_error(y_true, y_pred)\n",
    "# def custom_loss(y_true, y_pred, args):\n",
    "#     enc_loss = keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print(decoder.summary())\n",
    "print(encoder.summary())\n",
    "autoencoder.summary()\n",
    "def custom_loss(y_true, y_pred):\n",
    "    image_in = y_true\n",
    "    encode_true = encoder(image_in)\n",
    "    decode_true = decoder(encode_true)\n",
    "    print(image_in)\n",
    "    image_out = y_pred\n",
    "    print(image_out)\n",
    "    encoded = encoder(image_in)\n",
    "\n",
    "    loss3 = keras.losses.mean_absolute_error(y_true, y_pred)\n",
    "    return loss3\n",
    "decoder.compile(optimizer=opt, loss=\"mse\")\n",
    "autoencoder.compile(optimizer=opt, loss=custom_loss, metrics=[custom_loss])\n",
    "\n",
    "\n",
    "autoencoder.fit(x=x_train, y=[x_train,y_train], epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 17ms/step\n",
      "(1, 64)\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 403us/step\n",
      "(10000, 64)\n"
     ]
    }
   ],
   "source": [
    "example = encoder.predict(x_test[0].reshape(1, 28, 28, 1))\n",
    "print(example.shape)\n",
    "input_image = x_test[0].reshape(28, 28)\n",
    "example_image = example.reshape(8, 8)\n",
    "recoved_image = decoder.predict(example.reshape(1, 64))\n",
    "# Plot the images side by side\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
    "ax1.imshow(input_image)\n",
    "ax1.set_title(\"Input Image\")\n",
    "ax2.imshow(example_image)\n",
    "ax2.set_title(\"Encoded Image\")\n",
    "ax3.imshow(recoved_image.reshape(28, 28))\n",
    "ax3.set_title(\"Decoded Image\")\n",
    "plt.show()\n",
    "codes = encoder.predict(x_test.reshape(-1, 28, 28, 1))\n",
    "print(codes.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_62 (InputLayer)       [(None, 64)]              0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 784)               50960     \n",
      "                                                                 \n",
      " reshape_38 (Reshape)        (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,960\n",
      "Trainable params: 50,960\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " flatten_52 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,240\n",
      "Trainable params: 50,240\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " flatten_52 (Flatten)        (None, 784)               0         \n",
      "                                                                 \n",
      " dense_93 (Dense)            (None, 64)                50240     \n",
      "                                                                 \n",
      " input_61 (InputLayer)       multiple                  0         \n",
      "                                                                 \n",
      " dense_94 (Dense)            (None, 784)               50960     \n",
      "                                                                 \n",
      " reshape_38 (Reshape)        (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,200\n",
      "Trainable params: 101,200\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0250 - val_loss: 0.0123\n",
      "Epoch 2/10\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0106 - val_loss: 0.0096\n",
      "Epoch 3/10\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0090 - val_loss: 0.0087\n",
      "Epoch 4/10\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0085 - val_loss: 0.0084\n",
      "Epoch 5/10\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0081 - val_loss: 0.0080\n",
      "Epoch 6/10\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0078 - val_loss: 0.0078\n",
      "Epoch 7/10\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0077 - val_loss: 0.0077\n",
      "Epoch 8/10\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 9/10\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0076 - val_loss: 0.0076\n",
      "Epoch 10/10\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 0.0075 - val_loss: 0.0075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21552192088>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input = Input(shape=(28, 28, 1), name=\"img\")\n",
    "encoder_input_flat = layers.Flatten()(encoder_input)\n",
    "encoder_output = layers.Dense(64, activation=\"relu\")(encoder_input_flat)\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "\n",
    "decoder_input =  layers.InputLayer(input_shape=(64,))(encoder_output)\n",
    "x = layers.Dense(784, activation=\"relu\")(decoder_input)\n",
    "decoder_output = layers.Reshape((28, 28, 1))(x)\n",
    "decoder = keras.Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "autoencoder = keras.Model(encoder_input, decoder_output, name=\"autoencoder\")\n",
    "# def decoder_loss(y_true, y_pred):\n",
    "#     return keras.losses.mean_squared_error(y_true, y_pred)\n",
    "# def encoder_loss(y_true, y_pred):\n",
    "#     return keras.losses.mean_squared_error(y_true, y_pred)\n",
    "# def end_to_end_loss(y_true, y_pred):\n",
    "#     return keras.losses.mean_squared_error(y_true, y_pred)\n",
    "# def custom_loss(y_true, y_pred, args):\n",
    "#     enc_loss = keras.losses.mean_squared_error(y_true, y_pred)\n",
    "\n",
    "print(decoder.summary())\n",
    "print(encoder.summary())\n",
    "autoencoder.summary()\n",
    "\n",
    "decoder.compile(optimizer=opt, loss=\"mse\")\n",
    "autoencoder.compile(optimizer=opt, loss=\"mse\")\n",
    "\n",
    "\n",
    "autoencoder.fit(x_train, x_train, epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Cm   Ch        Bm        Bh         T\n",
      "0.0020 0.020  0.01  0.1  8.654914  8.626503  7.138389\n",
      "       0.070  0.01  0.1  7.385634  7.121985  5.208188\n",
      "       0.160  0.01  0.1  5.900273  5.417742  3.971776\n",
      "       0.320  0.01  0.1  5.047698  4.355993  3.201509\n",
      "0.0135 0.003  0.01  0.1  8.184879  8.136533  6.527816\n",
      "               sR   sG   sB\n",
      "0.0020 0.020  268  232  207\n",
      "       0.070  259  209  178\n",
      "       0.160  241  180  158\n",
      "       0.320  231  157  143\n",
      "0.0135 0.003  263  225  198\n",
      "bef norm x_train[0] [54. 39. 33.  0.  0.]\n",
      "aft norm x_train[0] [0.21176471 0.15294118 0.12941176 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "#load csv into \n",
    "# data_path = r\"C:\\Users\\joeli\\OneDrive\\Documents\\GitHub\\EncoderDecoder\\JJ_LUT.csv\"\n",
    "headers = \"Cm,Ch,Bm,Bh,T,sR,sG,sB\"\n",
    "# df = pd.read_csv(config.LUTv1_PATH, sep=\",\", header=None, names=headers.split(\",\"))\n",
    "# df = pd.read_csv(config.LUTv2_PATH, sep=\",\", header=None, names=headers.split(\",\"))\n",
    "# df = pd.read_csv(config.LUTv3_PATH, sep=\",\", header=None, names=headers.split(\",\"))\n",
    "\n",
    "df = pd.read_csv(r\"C:\\Users\\joeli\\OneDrive\\Documents\\GitHub\\Applied-Deep-Learning-with-Keras\\data\\JJ_LUTv1.csv\", sep=\",\", header=None, names=headers.split(\",\"))\n",
    "\n",
    "df.head()\n",
    "#remove header\n",
    "df = df.iloc[1:]\n",
    "#inputs = Cm,Ch,Bm,epi_thick\n",
    "y = df[['Cm','Ch','Bm','Bh','T']]\n",
    "print(y.head())\n",
    "\n",
    "#outputs = sR,sG,sB\n",
    "x = df[['sR','sG','sB']]\n",
    "print(x.head())\n",
    "\n",
    "df.head()\n",
    "#remove headers and convert to numpy array\n",
    "x = df[['sR','sG','sB']].iloc[1:].to_numpy()\n",
    "y = df[['Cm','Ch','Bm','Bh','T']].iloc[1:].to_numpy()\n",
    "#train nn on x,y\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42, shuffle=True)\n",
    "\n",
    "#numpy arrays\n",
    "x_train = np.asarray(x_train).reshape(-1,3).astype('float32')\n",
    "\n",
    "\n",
    "x_test = np.asarray(x_test).reshape(-1,3).astype('float32')\n",
    "\n",
    "\n",
    "#normalize\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "print(f\"aft norm x_train[0] {x_train[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 3)]               0         \n",
      "                                                                 \n",
      " dense_428 (Dense)           (None, 70)                280       \n",
      "                                                                 \n",
      " dense_429 (Dense)           (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_430 (Dense)           (None, 5)                 355       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,605\n",
      "Trainable params: 5,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_181 (InputLayer)      [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_432 (Dense)           (None, 70)                420       \n",
      "                                                                 \n",
      " dense_433 (Dense)           (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_434 (Dense)           (None, 3)                 213       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,603\n",
      "Trainable params: 5,603\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "call\n",
      "Model: \"my_model_92\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Functional)        (None, 5)                 5605      \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 3)                 5603      \n",
      "                                                                 \n",
      " autoencoder (Functional)    (None, 3)                 11238     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,238\n",
      "Trainable params: 11,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(1101, 3)\n",
      "(1101, 5)\n",
      "Epoch 1/10\n",
      "call\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1083, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 316, in __call__\n        total_total_loss_mean_value = tf.add_n(total_loss_mean_values)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\layers\\core\\tf_op_layer.py\", line 119, in handle\n        return TFOpLambda(op)(*args, **kwargs)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"tf.math.add_n_28\" (type TFOpLambda).\n    \n    Shapes must be equal rank, but are 0 and 1\n    \tFrom merging shape 0 with other shapes. for '{{node tf.math.add_n_28/AddN}} = AddN[N=2, T=DT_FLOAT](tf.math.add_n_28/AddN/mean_squared_error/weighted_loss/value, Placeholder)' with input shapes: [], [?].\n    \n    Call arguments received by layer \"tf.math.add_n_28\" (type TFOpLambda):\n      • inputs=['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(None,), dtype=float32)']\n      • name=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16048\\1193801516.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1083, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 316, in __call__\n        total_total_loss_mean_value = tf.add_n(total_loss_mean_values)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\layers\\core\\tf_op_layer.py\", line 119, in handle\n        return TFOpLambda(op)(*args, **kwargs)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"tf.math.add_n_28\" (type TFOpLambda).\n    \n    Shapes must be equal rank, but are 0 and 1\n    \tFrom merging shape 0 with other shapes. for '{{node tf.math.add_n_28/AddN}} = AddN[N=2, T=DT_FLOAT](tf.math.add_n_28/AddN/mean_squared_error/weighted_loss/value, Placeholder)' with input shapes: [], [?].\n    \n    Call arguments received by layer \"tf.math.add_n_28\" (type TFOpLambda):\n      • inputs=['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(None,), dtype=float32)']\n      • name=None\n"
     ]
    }
   ],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "    self.codes = codes\n",
    "    self.enc_in = Input(shape=(3), name=\"img\")\n",
    "\n",
    "    self.enc_d1 = layers.Dense(70, activation=\"relu\")(self.enc_in)\n",
    "    self.enc_d2 = layers.Dense(70, activation=\"relu\")(self.enc_d1)\n",
    "    self.enc_out = layers.Dense(5, activation=\"relu\")(self.enc_d2)\n",
    "    self.encoder = keras.Model(self.enc_in, self.enc_out, name=\"encoder\")\n",
    "    #call parent opt\n",
    "    \n",
    "    # self.encoder.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4), loss=\"mse\")\n",
    "    print(self.encoder.summary())\n",
    "    # self.dec_in =  layers.InputLayer(input_shape=(5,))(self.enc_out)\n",
    "    # self.dec_in = InputLayer(shape=(5), name=\"dec_in\")(self.enc_out)\n",
    "    self.dec_in = layers.Dense(5, activation=\"relu\")(self.enc_out)\n",
    "    self.dec_d1 = layers.Dense(70, activation=\"relu\")(self.dec_in)\n",
    "    self.dec_d2 = layers.Dense(70, activation=\"relu\")(self.dec_d1)\n",
    "    self.dec_out = layers.Dense(3, activation=\"relu\")(self.dec_d2)\n",
    "\n",
    "    self.decoder = keras.Model(self.dec_in, self.dec_out, name=\"decoder\")\n",
    "    # self.decoder.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4), loss=\"mse\")\n",
    "    print(self.decoder.summary())\n",
    "\n",
    "\n",
    "    self.autoencoder = keras.Model(self.enc_in, self.dec_out, name=\"autoencoder\")\n",
    "    self.autoencoder.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4), loss=\"mse\")\n",
    "\n",
    "  def call(self, inputs):\n",
    "    print(\"call\")\n",
    "    # self.decoder.add_loss(\"mse\")\n",
    "    # self.encoder.add_loss(\"mse\")\n",
    "    # self.encoder.add_loss(keras.losses.mean_squared_error(y_true=inputs, y_pred=self.dec_out))\n",
    "    #wrap your loss computation in a zero argument `lambda`\n",
    "    pixels = self.enc_in\n",
    "    enc = self.enc_out\n",
    "    dec = self.dec_out\n",
    "    # #convert to tensor\n",
    "    # pixels = tf.convert_to_tensor(pixels)\n",
    "    # enc = tf.convert_to_tensor(enc)\n",
    "    # dec = tf.convert_to_tensor(dec)\n",
    "    # self.autoencoder.add_loss(lambda: keras.losses.mean_squared_error(pixels, dec))\n",
    "    self.autoencoder.add_loss(lambda: keras.losses.mean_squared_error(inputs, dec))\n",
    "\n",
    "\n",
    "    # self.decoder.add_loss(keras.losses.mean_squared_error(y_true=inputs, y_pred=self.decoder_output))\n",
    "    return inputs\n",
    "\n",
    "\n",
    "model = MyModel()\n",
    "#build model\n",
    "model.build(input_shape=(None, 3))\n",
    "model.compile(loss=\"mse\")\n",
    "model.summary()\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "model.fit(x_train, x_train, epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "call\n",
      "Model: \"my_model_79\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " encoder (Functional)        (None, 5)                 5605      \n",
      "                                                                 \n",
      " decoder (Functional)        (None, 3)                 5603      \n",
      "                                                                 \n",
      " autoencoder (Functional)    (None, 3)                 11208     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,208\n",
      "Trainable params: 11,208\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "call\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1083, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 316, in __call__\n        total_total_loss_mean_value = tf.add_n(total_loss_mean_values)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\layers\\core\\tf_op_layer.py\", line 119, in handle\n        return TFOpLambda(op)(*args, **kwargs)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"tf.math.add_n_14\" (type TFOpLambda).\n    \n    Shapes must be equal rank, but are 0 and 1\n    \tFrom merging shape 0 with other shapes. for '{{node tf.math.add_n_14/AddN}} = AddN[N=2, T=DT_FLOAT](tf.math.add_n_14/AddN/mean_squared_error/weighted_loss/value, Placeholder)' with input shapes: [], [?].\n    \n    Call arguments received by layer \"tf.math.add_n_14\" (type TFOpLambda):\n      • inputs=['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(None,), dtype=float32)']\n      • name=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16048\\3712555274.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# model.compile(optimizer=model.opt, loss=\"mse\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1083, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 316, in __call__\n        total_total_loss_mean_value = tf.add_n(total_loss_mean_values)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\layers\\core\\tf_op_layer.py\", line 119, in handle\n        return TFOpLambda(op)(*args, **kwargs)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    ValueError: Exception encountered when calling layer \"tf.math.add_n_14\" (type TFOpLambda).\n    \n    Shapes must be equal rank, but are 0 and 1\n    \tFrom merging shape 0 with other shapes. for '{{node tf.math.add_n_14/AddN}} = AddN[N=2, T=DT_FLOAT](tf.math.add_n_14/AddN/mean_squared_error/weighted_loss/value, Placeholder)' with input shapes: [], [?].\n    \n    Call arguments received by layer \"tf.math.add_n_14\" (type TFOpLambda):\n      • inputs=['tf.Tensor(shape=(), dtype=float32)', 'tf.Tensor(shape=(None,), dtype=float32)']\n      • name=None\n"
     ]
    }
   ],
   "source": [
    "# model.build(input_shape=(None, 3))\n",
    "# model.summary()\n",
    "# # model.compile(optimizer=model.opt, loss=\"mse\")\n",
    "# model.fit(x_train, x_train, epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train, x_train, epochs=10, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_85 (InputLayer)       [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 70)                420       \n",
      "                                                                 \n",
      " dense_325 (Dense)           (None, 5)                 355       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 805\n",
      "Trainable params: 805\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 70)                420       \n",
      "                                                                 \n",
      " dense_320 (Dense)           (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 5)                 355       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,745\n",
      "Trainable params: 5,745\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " img (InputLayer)            [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_319 (Dense)           (None, 70)                420       \n",
      "                                                                 \n",
      " dense_320 (Dense)           (None, 70)                4970      \n",
      "                                                                 \n",
      " dense_321 (Dense)           (None, 5)                 355       \n",
      "                                                                 \n",
      " dense_322 (Dense)           (None, 5)                 30        \n",
      "                                                                 \n",
      " dense_324 (Dense)           (None, 70)                420       \n",
      "                                                                 \n",
      " dense_325 (Dense)           (None, 5)                 355       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6,550\n",
      "Trainable params: 6,550\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input tensor cannot be reached given provided output tensors. Please make sure the tensor KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name='img'), name='img', description=\"created by layer 'img'\") is included in the model inputs when building functional model.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24548\\4173354177.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoencoder_output\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoencoder_input\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mensemble_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[0mensemble_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mensemble_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, name, trainable, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m             ):\n\u001b[0;32m    163\u001b[0m                 inputs, outputs = functional_utils.clone_graph_nodes(\n\u001b[1;32m--> 164\u001b[1;33m                     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m                 )\n\u001b[0;32m    166\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\functional_utils.py\u001b[0m in \u001b[0;36mclone_graph_nodes\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[0mto\u001b[0m \u001b[0mcreate\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnew\u001b[0m \u001b[0mfunctional\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \"\"\"\n\u001b[1;32m--> 155\u001b[1;33m     \u001b[0mnodes_to_clone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_nodes_by_inputs_and_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m     \u001b[0mcloned_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m     \u001b[0mcloned_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\functional_utils.py\u001b[0m in \u001b[0;36mfind_nodes_by_inputs_and_outputs\u001b[1;34m(inputs, outputs)\u001b[0m\n\u001b[0;32m    117\u001b[0m                     \u001b[1;34m\"output tensors. Please make sure the tensor {} is \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m                     \u001b[1;34m\"included in the model inputs when building \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m                     \u001b[1;34m\"functional model.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m                 )\n\u001b[0;32m    121\u001b[0m             \u001b[0mnodes_to_visit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minbound_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input tensor cannot be reached given provided output tensors. Please make sure the tensor KerasTensor(type_spec=TensorSpec(shape=(None, 5), dtype=tf.float32, name='img'), name='img', description=\"created by layer 'img'\") is included in the model inputs when building functional model."
     ]
    }
   ],
   "source": [
    "encoder_input = Input(shape=(5,), name=\"img\")\n",
    "x = layers.Dense(70, activation=\"relu\")(encoder_input)\n",
    "x = layers.Dense(70, activation=\"relu\")(x)\n",
    "encoder_output = layers.Dense(5, activation=\"relu\")(x)\n",
    "encoder = keras.Model(encoder_input, encoder_output, name=\"encoder\")\n",
    "# encoder.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4), loss=\"mse\")\n",
    "decoder_input =  layers.Dense(5, activation=\"relu\")(encoder_output)\n",
    "x = layers.Dense(70, activation=\"relu\")(decoder_input)\n",
    "x = layers.Dense(70, activation=\"relu\")(decoder_input)\n",
    "decoder_output = layers.Dense(5, activation=\"relu\")(x)\n",
    "decoder = keras.Model(encoder_output, decoder_output, name=\"decoder\")\n",
    "autoencoder_input = encoder_output\n",
    "autoencoder_output = decoder_output\n",
    "autoencoder = keras.Model(encoder_input,decoder_output, name=\"autoencoder\")\n",
    "\n",
    "print(decoder.summary())\n",
    "print(encoder.summary())\n",
    "autoencoder.summary()\n",
    " \n",
    "opt = Adam(lr=1e-4)\n",
    "losses ={ \"encoder\": \"mse\", \"decoder\": \"mse\", \"autoencoder\": \"mse\"}\n",
    "loss_weights = {\"encoder\":.33, \"decoder\":.33, \"autoencoder\": .33}\n",
    "# autoencoder.compile(optimizer=opt, loss=losses,loss_weights=loss_weights, metrics=['accuracy'])\n",
    "outputs = keras.layers.average([encoder_output, decoder_output, autoencoder_output])\n",
    "inputs = keras.layers.concatenate([encoder_input, decoder_input, autoencoder_input], axis=0)\n",
    "ensemble_model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "ensemble_model.compile(optimizer=opt, loss=losses,loss_weights=loss_weights, metrics=['accuracy'])\n",
    "ensemble_model.summary()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Model Compiling\n",
    "# model.compile(optimizer=opt, loss=losses,metrics=\"accuracy\")\n",
    "\n",
    "# Model Fitting\n",
    "# H = autoencoder.fit(x=[x_train, y_train, x_train],\n",
    "# y={'encoder': y_train, 'decoder': x_train , 'autoencoder': x_train},\n",
    "# \tvalidation_data=([x_test, y_test, x_test],\n",
    "#     \t{'encoder': y_test, 'decoder': x_test , 'autoencoder': x_test}), epochs=10, batch_size=128)\n",
    "                            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AutoEncoder(Model):\n",
    "  def __init__(self):\n",
    "    super(AutoEncoder, self).__init__()\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Dense(3, activation=\"relu\"),\n",
    "      layers.Dense(70, activation=\"relu\"),\n",
    "      layers.Dense(70, activation=\"relu\"),\n",
    "      layers.Dense(5, activation=\"relu\")])\n",
    "\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(16, activation=\"relu\"),\n",
    "      layers.Dense(32, activation=\"relu\"),\n",
    "      layers.Dense(140, activation=\"sigmoid\")])\n",
    "\n",
    "  def call(self, x ):\n",
    "    encoded = self.encoder(x)\n",
    "\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded, encoded, \n",
    "\n",
    "autoencoder = AutoEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1083, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\losses.py\", line 1641, in mean_absolute_error\n        return backend.mean(tf.abs(y_pred - y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 140 and 28 for '{{node mean_absolute_error/sub}} = Sub[T=DT_FLOAT](auto_encoder/sequential_1/dense_331/Sigmoid, mean_absolute_error/Cast)' with input shapes: [32,28,140], [32,28,28].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24548\\210033947.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                 validation_data=(x_test, x_test))\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                     \u001b[0mretval_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                 \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\training.py\", line 1083, in compute_loss\n        y, y_pred, sample_weight, regularization_losses=self.losses\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"c:\\Users\\joeli\\anaconda3\\envs\\robot_tf\\lib\\site-packages\\keras\\losses.py\", line 1641, in mean_absolute_error\n        return backend.mean(tf.abs(y_pred - y_true), axis=-1)\n\n    ValueError: Dimensions must be equal, but are 140 and 28 for '{{node mean_absolute_error/sub}} = Sub[T=DT_FLOAT](auto_encoder/sequential_1/dense_331/Sigmoid, mean_absolute_error/Cast)' with input shapes: [32,28,140], [32,28,28].\n"
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss='mae')\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow._api.v2.train' has no attribute 'Saver'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24548\\2448116325.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"mse\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m## Call Saver to save the model and re-use it later during evaluation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow._api.v2.train' has no attribute 'Saver'"
     ]
    }
   ],
   "source": [
    "## Set params\n",
    "n_epochs = 100\n",
    "loss = \"mse\"\n",
    "## Call Saver to save the model and re-use it later during evaluation\n",
    "saver = tf.train.Saver()\n",
    "batch_size = tf.placeholder(tf.int64, shape=[])\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    # initialise iterator with train data\n",
    "    sess.run(iter.initializer, feed_dict={x: x_train,\n",
    "                                          batch_size: 128})\n",
    "    print('Training...')\n",
    "    print(sess.run(x_train).shape) \n",
    "    for epoch in range(n_epochs):       \n",
    "        for iteration in range(x_train.shape[0] // 128):\n",
    "            sess.run(x_train)\n",
    "        if epoch % 10 == 0:\n",
    "            loss_train = loss.eval()   # not shown\n",
    "            print(\"\\r{}\".format(epoch), \"Train MSE:\", loss_train) \n",
    "        #saver.save(sess, \"./my_model_all_layers.ckpt\") \n",
    "    save_path = saver.save(sess, \"./model.ckpt\")    \n",
    "    print(\"Model saved in path: %s\" % save_path)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Parametric-t-SNE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
